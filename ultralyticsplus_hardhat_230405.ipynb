{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8680a1bd",
   "metadata": {
    "id": "8680a1bd"
   },
   "source": [
    "### Install repository to allows IPython to use Google Drive for file management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97cfa7c",
   "metadata": {
    "id": "d97cfa7c"
   },
   "outputs": [],
   "source": [
    "#git clone git://github.com/jupyter/jupyter-drive.git\n",
    "#pip install -e jupyter-drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2346581",
   "metadata": {
    "id": "b2346581"
   },
   "source": [
    "### To install the notebook extension and activate your configuration with Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8945cde9",
   "metadata": {
    "id": "8945cde9"
   },
   "outputs": [],
   "source": [
    "#python -m jupyterdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49450241",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49450241",
    "outputId": "a91d9b67-dbf8-48b1-e9fb-2fbf5f78a2c5"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bil8BdXsiuYN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bil8BdXsiuYN",
    "outputId": "4cadaa11-2411-4284-c733-629b62e0ab80"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HaQgrtA5ixYU",
   "metadata": {
    "id": "HaQgrtA5ixYU"
   },
   "outputs": [],
   "source": [
    "DataFolder = \"/content/drive/MyDrive/SDAAI/Capstone-Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LAZxnFlSeivS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAZxnFlSeivS",
    "outputId": "ea8480aa-991e-463e-9bd7-dd4fe0cea194"
   },
   "outputs": [],
   "source": [
    "pip install ultralyticsplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sJx595MZmMRF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJx595MZmMRF",
    "outputId": "b056f252-0cf6-46bb-9788-51bd6b247c42"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UaBoz7FrjTtG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaBoz7FrjTtG",
    "outputId": "4798c809-9842-4221-df2d-af4e0eb0e49e"
   },
   "outputs": [],
   "source": [
    "#image_path = DataFolder+\"/Safety Hat/Images/hard_hat_workers0.png\" # or file, Path, PIL, OpenCV, numpy, list\n",
    "image_path = DataFolder+\"/Safety-Hat/Images/Helmet-Example01.jpg\"\n",
    "\n",
    "# Inference\n",
    "results = model(image_path) \n",
    "\n",
    "# Results\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eihFAsSlon6O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "id": "eihFAsSlon6O",
    "outputId": "2875db12-6b27-449b-dfcb-0f384639827e"
   },
   "outputs": [],
   "source": [
    "results.show()\n",
    "print(results.pandas().xyxy[0])\n",
    "\n",
    "for i in range(len(results.pandas().xyxy[0].name)):\n",
    "    print(\"Object\",i,results.pandas().xyxy[0].name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d6b94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "id": "810d6b94",
    "outputId": "e62dfc39-6f36-4fcb-e863-7e36370b47dd"
   },
   "outputs": [],
   "source": [
    "from ultralyticsplus import YOLO, render_result\n",
    "\n",
    "# load model\n",
    "model = YOLO('keremberke/yolov8m-hard-hat-detection')\n",
    "\n",
    "# set model parameters\n",
    "model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "model.overrides['max_det'] = 1000  # maximum number of detections per image\n",
    "\n",
    "# set image\n",
    "#image = 'https://github.com/RP-SDAAI/Capstone-Project/blob/72573878f2546c1c2984c3e1006ef8e7c72672ec/Helmet-Example01.jpg'\n",
    "\n",
    "#image = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
    "\n",
    "# perform inference\n",
    "results = model.predict(image_path)\n",
    "\n",
    "# observe results\n",
    "print(results[0].boxes)\n",
    "render = render_result(model=model, image=image_path, result=results[0])\n",
    "render.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k0HWQ1MO4vUK",
   "metadata": {
    "id": "k0HWQ1MO4vUK"
   },
   "source": [
    "## Camera Capture  \n",
    "### Using a webcam to capture images for processing on the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Usyq_XqTdW2o",
   "metadata": {
    "id": "Usyq_XqTdW2o"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6T5YsxJKds3G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "6T5YsxJKds3G",
    "outputId": "c52fbeb1-0c22-4c8f-e160-1438b94bdde9"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  print('Saved to {}'.format(filename))\n",
    "  \n",
    "  # Show the image which was just taken.\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xoMxZCjbd3vW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "xoMxZCjbd3vW",
    "outputId": "20f3ce92-0b5b-49aa-dab6-d9f51788401f"
   },
   "outputs": [],
   "source": [
    "from ultralyticsplus import YOLO, render_result\n",
    "\n",
    "def safety_helmet():\n",
    "\n",
    "    # load model\n",
    "    model = YOLO('keremberke/yolov8m-hard-hat-detection')\n",
    "\n",
    "    # set model parameters\n",
    "    model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "    model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "    model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "    model.overrides['max_det'] = 1000  # maximum number of detections per image\n",
    "\n",
    "# set image\n",
    "#image = 'https://github.com/RP-SDAAI/Capstone-Project/blob/72573878f2546c1c2984c3e1006ef8e7c72672ec/Helmet-Example01.jpg'\n",
    "\n",
    "#image = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
    "\n",
    "# perform inference\n",
    "#results = model.predict(image_path)\n",
    "    results = model.predict(filename)\n",
    "\n",
    "#    self.assertEqual(array.shape, (1, 224, 224, 3))\n",
    "\n",
    "# observe results\n",
    "    print(results[0].boxes)\n",
    "    render = render_result(model=model, image=filename, result=results[0])\n",
    "    render.show()\n",
    "\n",
    "\n",
    "safety_helmet()\n",
    "\n",
    "\n",
    "## deploy in actual scenario, i need a device to run the code. (e.g. raspberry pi, nano jetson. laptop)\n",
    "## run python (*.py) locally for streaming video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralyticsplus import YOLO, render_result\n",
    "\n",
    "def safety_helmet01(frame):\n",
    "\n",
    "    # load model\n",
    "    model = YOLO('keremberke/yolov8m-hard-hat-detection')\n",
    "\n",
    "    # set model parameters\n",
    "    model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "    model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "    model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "    model.overrides['max_det'] = 1000  # maximum number of detections per image\n",
    "\n",
    "# set image\n",
    "#image = 'https://github.com/RP-SDAAI/Capstone-Project/blob/72573878f2546c1c2984c3e1006ef8e7c72672ec/Helmet-Example01.jpg'\n",
    "\n",
    "#image = 'https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg'\n",
    "\n",
    "# perform inference\n",
    "#results = model.predict(image_path)\n",
    "    results = model.predict(frame)\n",
    "\n",
    "#    self.assertEqual(array.shape, (1, 224, 224, 3))\n",
    "\n",
    "# observe results\n",
    "    print(results[0].boxes)\n",
    "    render = render_result(model=model, image=frame, result=results[0])\n",
    "    #render.show()\n",
    "    return render\n",
    "\n",
    "\n",
    "#safety_helmet()\n",
    "\n",
    "\n",
    "## deploy in actual scenario, i need a device to run the code. (e.g. raspberry pi, nano jetson. laptop)\n",
    "## run python (*.py) locally for streaming video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLaypxEz4dNJ",
   "metadata": {
    "id": "iLaypxEz4dNJ"
   },
   "source": [
    "#Need help to get working code for streaming video on google colab\n",
    "\n",
    "Need to run streaming in local hardware e.g. jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09VDWx93EHj0",
   "metadata": {
    "id": "09VDWx93EHj0"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(0) # For streaming links (#0 : Computer Webcam. Otherwise need to know the RTSP Url of the Webcam, or the IP address that connect directly to the CCTV)\n",
    "while True:\n",
    "    rdy,frame = vid.read()\n",
    "    print(rdy)\n",
    "    try:\n",
    "    ##process frame to infer the model\n",
    "        processframe = safety_helmet01(frame)\n",
    "    \n",
    "        cv2.imshow('Video Live IP cam', processframe)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key ==ord('q'):\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8r01bSQV4na3",
   "metadata": {
    "id": "8r01bSQV4na3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Gv385cYm4ro4",
   "metadata": {
    "id": "Gv385cYm4ro4"
   },
   "source": [
    "#Install Gradio for model deployment  \n",
    "#### Reference: https://github.com/gradio-app/gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b480e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "193b480e",
    "outputId": "9fc12981-a092-4399-a3ff-94fc206819be"
   },
   "outputs": [],
   "source": [
    "!pip install gradio\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7JolM_Sc7J2_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7JolM_Sc7J2_",
    "outputId": "2eb3910f-c5cd-449b-bc24-2a178d494d5a"
   },
   "outputs": [],
   "source": [
    "import gradio as gr  (##running streaming video on gradio will incur charge)\n",
    "\n",
    "#def test_preprocessing(self):\n",
    "#        inp = inputs.Webcam(0)\n",
    "#        array = inp.preprocess(BASE64_IMG)\n",
    "#        self.assertEqual(array.shape, (1, 224, 224, 3))\n",
    "\n",
    "\n",
    "##Check with lecturer on the following code ####\n",
    "\n",
    "#demo = gr.Interface(fn=safety_helmet, inputs=\"image\", outputs=\"image\")\n",
    "\n",
    "demo = gr.Interface(fn=safety_helmet, inputs=take_photo(), outputs=safety_helmet(), description=\"Safety Helmet Detection\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K1IjcYZL4zoY",
   "metadata": {
    "id": "K1IjcYZL4zoY"
   },
   "outputs": [],
   "source": [
    "##Sample Gradio code \n",
    "#import gradio as gr\n",
    "\n",
    "#def greet(name):\n",
    "#    return \"Hello \" + name + \"!\"\n",
    "\n",
    "#demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "\n",
    "#fn: the function to wrap a UI around\n",
    "#inputs: which component(s) to use for the input (e.g. \"text\", \"image\" or \"audio\")\n",
    "#outputs: which component(s) to use for the output (e.g. \"text\", \"image\" or \"label\")\n",
    "\n",
    "\n",
    "#demo.launch(share=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
